{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_RNN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOsBXDCcPuCVbLcgpPyIkkD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["In this project we will create a model to predict on a motion discrimination dataset. The model consists of two 2D convolutional LSTM layer followed by a flattening layer and 3 fully connected layers. The dataset used for training and testing consists of thousands of short videos with a black background. There are white dots on the screen which will move either left or right. The model's task is to determine which direction the dots are moving in the video. We will use the keras framework from the Tensorflow library to build, train and evaluate the performance of this model. We will use numpy and pandas libraries for working with our dataset and preparing the examples for training and testing. We use the cv2 library for reading in the frame data from the video files. Finally, we will use google drive to store folders of the data."],"metadata":{"id":"4zZoB_NKoxDe"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLxGxhESBrWC","executionInfo":{"status":"ok","timestamp":1649808518258,"user_tz":240,"elapsed":30225,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}},"outputId":"c430ee3f-9116-4c9d-e1dd-119bb70970ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from tensorflow import keras\n","from keras.layers import BatchNormalization, Dense, MaxPooling3D, Flatten, Conv2D, Reshape, ConvLSTM2D, LeakyReLU, Dropout\n","from imutils import paths\n","\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import imageio\n","import cv2\n","import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","source":["The root path will be used to access the data. Please change this to the path in which this file resides. "],"metadata":{"id":"DrEPAkuAqN0p"}},{"cell_type":"code","source":["root_path = 'gdrive/My Drive/Colab Notebooks/Research'  #change root_path to your project folder, where the .ipynb file is stored"],"metadata":{"id":"frT-2olbBwsX","executionInfo":{"status":"ok","timestamp":1649808518258,"user_tz":240,"elapsed":11,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["The IMG_SIZE is a constant that determines the dimmension to which the frames of the video will be cropped. For example, IMG_SIZE = 32 will result in a frame shape of 32x32. BATCH_SIZE is a constant that will break the training data into batches of that size. EPOCHS is a constant that determines the number of iterations for which the model will be trained. MAX_SEQ_LENGTH is a variable that cuts the number of frames down to its value. For example, if a video file containing a video with 30 frames is input then the total number of frames for that example will be cropped to the first MAX_SEQ_LENGTH number of frames. This helps reduce the amount of RAM used and the runtime. "],"metadata":{"id":"tBzFwu5zqcmz"}},{"cell_type":"code","source":["IMG_SIZE = 32 #represents the height and width of the frame\n","BATCH_SIZE = 8\n","EPOCHS =10\n","\n","MAX_SEQ_LENGTH = 10 #represents the number of frames \n","num_models = 3 #number of models that are trained and returned when calling get_models() "],"metadata":{"id":"nXRfgG5dBzMD","executionInfo":{"status":"ok","timestamp":1649808518260,"user_tz":240,"elapsed":10,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["This cell reads the data into two different data frames: train_df and test_df. These dataframes contain the filenames for all of the training and testing video examples. "],"metadata":{"id":"y0GWMI-SreO_"}},{"cell_type":"code","source":["data_path = root_path + \"/Data2/train/DataFile2.csv\"\n","test_data_path = root_path + \"/Data2/test/TestData2File.csv\"\n","train_df = pd.read_csv(data_path)\n","test_df = pd.read_csv(test_data_path)\n","\n","# shuffle the DataFrame rows\n","train_df = train_df.sample(frac = 1)\n","test_df = test_df.sample(frac = 1)    \n","\n","\n","\n","\n","print(f\"Total videos for training: {len(train_df)}\")\n","print(f\"Total videos for testing: {len(test_df)}\")\n","\n","train_df.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"HK-csZuBB1mb","executionInfo":{"status":"ok","timestamp":1649808532302,"user_tz":240,"elapsed":14051,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}},"outputId":"0231bea6-489f-40ad-9e14-5428413dce04"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Total videos for training: 2000\n","Total videos for testing: 686\n"]},{"output_type":"execute_result","data":{"text/plain":["          file_name  label\n","361    test1472.avi  Right\n","1160   test2271.avi   Left\n","1638   test2749.avi   Left\n","1572   test2683.avi   Left\n","226    test1337.avi  Right\n","678    test1789.avi  Right\n","1695  test27106.avi   Left\n","475    test1586.avi  Right\n","405    test1516.avi  Right\n","95    test11106.avi  Right"],"text/html":["\n","  <div id=\"df-b5cd7af1-638f-4a07-afc3-ec8b8ec9d0c4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>361</th>\n","      <td>test1472.avi</td>\n","      <td>Right</td>\n","    </tr>\n","    <tr>\n","      <th>1160</th>\n","      <td>test2271.avi</td>\n","      <td>Left</td>\n","    </tr>\n","    <tr>\n","      <th>1638</th>\n","      <td>test2749.avi</td>\n","      <td>Left</td>\n","    </tr>\n","    <tr>\n","      <th>1572</th>\n","      <td>test2683.avi</td>\n","      <td>Left</td>\n","    </tr>\n","    <tr>\n","      <th>226</th>\n","      <td>test1337.avi</td>\n","      <td>Right</td>\n","    </tr>\n","    <tr>\n","      <th>678</th>\n","      <td>test1789.avi</td>\n","      <td>Right</td>\n","    </tr>\n","    <tr>\n","      <th>1695</th>\n","      <td>test27106.avi</td>\n","      <td>Left</td>\n","    </tr>\n","    <tr>\n","      <th>475</th>\n","      <td>test1586.avi</td>\n","      <td>Right</td>\n","    </tr>\n","    <tr>\n","      <th>405</th>\n","      <td>test1516.avi</td>\n","      <td>Right</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>test11106.avi</td>\n","      <td>Right</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5cd7af1-638f-4a07-afc3-ec8b8ec9d0c4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b5cd7af1-638f-4a07-afc3-ec8b8ec9d0c4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b5cd7af1-638f-4a07-afc3-ec8b8ec9d0c4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["The crop_center_square function takes in a frame as an argument and outputs an array containing the the center of the frame. The load_video function takes in the path or filename of an example, the maximum frames the processed example should have, and what shape to form the example into. This function will return a numpy array containing the rgb values of a specific video example. The numpy output shape is (MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3)."],"metadata":{"id":"JwHeLP8Ortcb"}},{"cell_type":"code","source":["# The following two methods are taken from this tutorial:\n","# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n","\n","\n","def crop_center_square(frame):\n","    y, x = frame.shape[0:2]\n","    min_dim = min(y, x)\n","    start_x = (x // 2) - (min_dim // 2)\n","    start_y = (y // 2) - (min_dim // 2)\n","    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n","\n","\n","def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n","    path = root_path +\"/Data2/\" + path\n","    cap = cv2.VideoCapture(path)\n","    frames = []\n","    try:\n","        while True:\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            frame = crop_center_square(frame)\n","            frame = cv2.resize(frame, resize)\n","            frame = frame[:, :, [2, 1, 0]]\n","            frames.append(frame)\n","\n","            if len(frames) == max_frames:\n","                break\n","    finally:\n","        cap.release()\n","    return np.array(frames)"],"metadata":{"id":"xRKd8RbCB5wK","executionInfo":{"status":"ok","timestamp":1649808532303,"user_tz":240,"elapsed":7,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["This cell converts the y-values (either \"Left\" or \"Right\") to binary representations."],"metadata":{"id":"4BUnN4qZsvZm"}},{"cell_type":"code","source":["label_processor = keras.layers.StringLookup(\n","    num_oov_indices=0, vocabulary=np.unique(train_df[\"label\"])\n",")\n","print(label_processor.get_vocabulary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eu_6EgAdB9B1","executionInfo":{"status":"ok","timestamp":1649808535313,"user_tz":240,"elapsed":3016,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}},"outputId":"dab550c8-46f9-4c1e-ebfc-712becf52018"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['Left', 'Right']\n"]}]},{"cell_type":"markdown","source":["The prepare_all_videos function loads in the dataset from a dataframe and returns the x-values (a numpy array of shape (number of examples, MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3)) and the y-values (a numpy array of shape (number of examples, 1). "],"metadata":{"id":"RmABA6pFtBdi"}},{"cell_type":"code","source":["def prepare_all_videos(df, root_dir):\n","    num_samples = len(df)\n","    print(\"num_samples:\", num_samples)\n","    video_paths = df[\"file_name\"].values.tolist()\n","    labels = df[\"label\"].values\n","    labels = label_processor(labels[..., None]).numpy() #now labels is a binary numpy array with values representing right and left\n","\n","    \n","    frame_features = np.zeros(\n","        shape=(num_samples, MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3), dtype=\"float32\"\n","    )\n","    \n","\n","    # For each video.\n","    for idx, path in enumerate(video_paths):\n","        video = load_video(os.path.join(root_dir, path))\n","        if idx%100 == 0:\n","          print(idx)\n","\n","\n","        for i, frame in enumerate(video): #this will take the first MAX_SEQ_LENGTH number of frames and return the new numpy array representing the video\n","          if i < MAX_SEQ_LENGTH:\n","            frame_features[idx, i] = video[i]\n","          else:\n","            break\n","        \n","\n","    return frame_features, labels\n","\n","\n","\n"],"metadata":{"id":"k1cV-3VE-r77","executionInfo":{"status":"ok","timestamp":1649808535314,"user_tz":240,"elapsed":4,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["The build_CNN_RNN function creates a keras sequential model consisting of 8 layers. The first layer is a 2 dimensional convolutional LSTM layer with 8 filters and a kernel size of 3x3. Next, there is a layer that adds non-linearity to the model. These two layers are then repeated again. Next, is a flattening layer that outputs a vector of values for the following dense layer. The first dense layer has 32 neurons and the second dense layer has 16 neurons. Both of these fully connected layers have a relu activation function. The final layer is a dense layer with 2 neurons and a softmax activation function. This cell builds the model and prints the model summary. "],"metadata":{"id":"Det9SvRNuCxs"}},{"cell_type":"code","source":["def build_CNN_RNN():\n","  model = keras.Sequential()\n","\n","\n","  model.add(ConvLSTM2D(8, kernel_size=(3,3), padding='same', return_sequences=True, input_shape=(MAX_SEQ_LENGTH, IMG_SIZE, IMG_SIZE, 3)))\n","  model.add(LeakyReLU())\n","  model.add(ConvLSTM2D(8, kernel_size=(3,3), padding='same', return_sequences=False))\n","  model.add(LeakyReLU())\n","  model.add(Flatten())\n","  model.add(Dense(32, activation='relu'))\n","  model.add(Dense(16, activation='relu'))\n","  model.add(Dense(2,activation='softmax'))\n","  return model\n","model = build_CNN_RNN()\n","model.summary()"],"metadata":{"id":"FabyHZRVB_hx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649808536830,"user_tz":240,"elapsed":1520,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}},"outputId":"b4a83537-38fc-4dea-8bc2-05bbf553c0fe"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv_lstm2d (ConvLSTM2D)    (None, 10, 32, 32, 8)     3200      \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 10, 32, 32, 8)     0         \n","                                                                 \n"," conv_lstm2d_1 (ConvLSTM2D)  (None, 32, 32, 8)         4640      \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 8)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," dense (Dense)               (None, 32)                262176    \n","                                                                 \n"," dense_1 (Dense)             (None, 16)                528       \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 34        \n","                                                                 \n","=================================================================\n","Total params: 270,578\n","Trainable params: 270,578\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"V1G82GuO-tez","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649808536831,"user_tz":240,"elapsed":18,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}},"outputId":"dd0a1f52-bc66-491d-a44a-37874cb7eeb0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","source":["This cell compiles the model, sets the learning rate and optimizer, and fits the model to the training data. The model is then evaluated using the testing data. "],"metadata":{"id":"tR58YaUWu8Br"}},{"cell_type":"code","source":["# Compile the model\n","def compile_model(my_model, train_data, train_labels):\n","  my_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n","              optimizer=tf.keras.optimizers.Adam(learning_rate=.01),\n","              metrics=['accuracy']) #passes in parameters required to define the model\n","\n","  filepath = \"/tmp/video_classifier\"\n","  checkpoint = keras.callbacks.ModelCheckpoint(\n","          filepath, save_weights_only=True, save_best_only=True, verbose=1\n","      ) # if you would like to save the weights of the best model during training then you can uncomment the line in history below\n","\n","  # Fit data to model\n","  history = my_model.fit(train_data,\n","          train_labels,\n","          batch_size=BATCH_SIZE,\n","          validation_split=0.3,\n","          epochs=EPOCHS,\n","          # checkpoints=[checkpoint]\n","          )\n","  return my_model"],"metadata":{"id":"RON3GK8pCG2Q","executionInfo":{"status":"ok","timestamp":1649808536831,"user_tz":240,"elapsed":5,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["The get_models function manages the calls to compile and build more models. The purpose of this function is to be able to pass in how many trained models are required (num_models) as well as the training data and labels and this function will return a list of the models."],"metadata":{"id":"cozCvIpIyAFd"}},{"cell_type":"code","source":["def get_models(num_models, train_data, train_labels):\n","  models = [] #a list of length num_models that contains all of the models trained on a specific MAX_SEQ_LENGTH value\n","  for i in range(num_models):\n","    built_model = build_CNN_RNN()\n","    comp_model = compile_model(built_model, train_data, train_labels)\n","    models.append(comp_model)\n","  return models\n","\n","\n"],"metadata":{"id":"Iia-qy94yDHq","executionInfo":{"status":"ok","timestamp":1649808536831,"user_tz":240,"elapsed":4,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["A new noisy test set is loaded into a pandas dataframe. The noisy test set has a lower correlation value. This means that a smaller percentage of the dots on the screen in a given example are actually moving the labeled direction (either left or right)."],"metadata":{"id":"-D5xUMGNy1FU"}},{"cell_type":"code","source":["noise_data_path = root_path + \"/Data2/noise_data/NoiseDataFile.csv\"\n","noise_df = pd.read_csv(noise_data_path)\n","\n","# shuffle the DataFrame rows\n","noise_df = noise_df.sample(frac = 1)\n","\n","\n","print(f\"Total videos for noisy testing: {len(noise_df)}\")\n","\n","noise_df.sample(10)\n","\n"],"metadata":{"id":"jsqM1G0byzeV","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"ok","timestamp":1649808539807,"user_tz":240,"elapsed":2980,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}},"outputId":"7d728a3c-0ff0-4f76-c27f-0d489eb01224"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Total videos for noisy testing: 686\n"]},{"output_type":"execute_result","data":{"text/plain":["        file_name  label\n","65   test1233.avi  Right\n","492  test2413.avi   Left\n","181  test1457.avi  Right\n","551  test2526.avi   Left\n","620  test2655.avi   Left\n","175  test1451.avi  Right\n","470  test2352.avi   Left\n","526  test2462.avi   Left\n","681  test2773.avi   Left\n","179  test1455.avi  Right"],"text/html":["\n","  <div id=\"df-9e1bf0d7-1476-4861-a2c2-36dfc8c26c8a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>65</th>\n","      <td>test1233.avi</td>\n","      <td>Right</td>\n","    </tr>\n","    <tr>\n","      <th>492</th>\n","      <td>test2413.avi</td>\n","      <td>Left</td>\n","    </tr>\n","    <tr>\n","      <th>181</th>\n","      <td>test1457.avi</td>\n","      <td>Right</td>\n","    </tr>\n","    <tr>\n","      <th>551</th>\n","      <td>test2526.avi</td>\n","      <td>Left</td>\n","    </tr>\n","    <tr>\n","      <th>620</th>\n","      <td>test2655.avi</td>\n","      <td>Left</td>\n","    </tr>\n","    <tr>\n","      <th>175</th>\n","      <td>test1451.avi</td>\n","      <td>Right</td>\n","    </tr>\n","    <tr>\n","      <th>470</th>\n","      <td>test2352.avi</td>\n","      <td>Left</td>\n","    </tr>\n","    <tr>\n","      <th>526</th>\n","      <td>test2462.avi</td>\n","      <td>Left</td>\n","    </tr>\n","    <tr>\n","      <th>681</th>\n","      <td>test2773.avi</td>\n","      <td>Left</td>\n","    </tr>\n","    <tr>\n","      <th>179</th>\n","      <td>test1455.avi</td>\n","      <td>Right</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e1bf0d7-1476-4861-a2c2-36dfc8c26c8a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9e1bf0d7-1476-4861-a2c2-36dfc8c26c8a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9e1bf0d7-1476-4861-a2c2-36dfc8c26c8a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["This cell contains much of the computation of the document. Performance is a numpy array that contains performance data on 15 different models. This cell starts by assigning a value to MAX_SEQ_LENGTH starting with 1 and going to 5. Then, the training data and labels as well as the noisy data and labels for testing are loaded. The datasets need to be reloaded each time because this will change the shape of the numpy arrays. Scores is an array that contains the performance for the models that are trained on a specific MAX_SEQ_LENGTH number. Each of the three models are trained on the training data set (which has been cropped to the correct number of frames). Each of the three models performances on the noisy data set are saved in the performance array. Then, the MAX_SEQ_LENGTH value is increased and the process is repeated. This continues until three models are trained for five different values for number of frames (MAX_SEQ_LENGTH values). Next, a graph is created to show how the number of frames in a video impacts the algorithm's performance on the motion discrimination problem. The number of frames in the data videos are plotted on the x-axis and the average of the three models' performance is graphed on the y-axis. This cell can be expected to take 1-2 hours to finish running if you are using collab pro. "],"metadata":{"id":"VJXWjZjv6E5y"}},{"cell_type":"code","source":["performance = np.zeros((5,3)) #contains the performance of 3 models for each of the 5 values of MAX_SEQ_LENGTH. Performance is on the noisy dataset\n","for length in range(1,6):\n","  MAX_SEQ_LENGTH = length\n","  train_data, train_labels = prepare_all_videos(train_df, \"train\")\n","  noise_data, noise_labels = prepare_all_videos(noise_df, \"noise_data\")\n","  print(f\"Frame features in train set: {train_data.shape}\")\n","  print(f\"Frame features in train set: {train_labels.shape}\")\n","\n","\n","  \n","\n","\n","\n","  scores = np.zeros((3))\n","  eval_models = get_models(num_models, train_data, train_labels)\n","  for i in range(len(eval_models)):\n","    score = eval_models[i].evaluate(noise_data, noise_labels, verbose=0)\n","    scores[i] = (round((score[1]*100),3))\n","  performance[length-1] = scores\n","  print(\"performance update:\", performance)\n","  \n","plt.plot(np.array(range(1,6)), np.average(performance,axis=1))\n","plt.title('How the Number of Frames in the Video Impacts Model Performance')\n","plt.ylabel('Average Accuracy (%)')\n","plt.xlabel('Number of Frames in the Video')\n","plt.show()\n","  \n","\n"],"metadata":{"id":"KPGVT2BuDeeU","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1649815033994,"user_tz":240,"elapsed":1933247,"user":{"displayName":"Rory Brown","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13219832983765992393"}},"outputId":"be1e7f24-264c-448a-d483-425c2142d96a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["num_samples: 2000\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","num_samples: 686\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","Frame features in train set: (2000, 1, 32, 32, 3)\n","Frame features in train set: (2000, 1)\n","Epoch 1/10\n","175/175 [==============================] - 15s 15ms/step - loss: 0.7003 - accuracy: 0.4736 - val_loss: 0.6910 - val_accuracy: 0.5183\n","Epoch 2/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6845 - accuracy: 0.5636 - val_loss: 0.7011 - val_accuracy: 0.5150\n","Epoch 3/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.5900 - accuracy: 0.6900 - val_loss: 0.9030 - val_accuracy: 0.5033\n","Epoch 4/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.4238 - accuracy: 0.7814 - val_loss: 1.3644 - val_accuracy: 0.4917\n","Epoch 5/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.2688 - accuracy: 0.8800 - val_loss: 1.2935 - val_accuracy: 0.4983\n","Epoch 6/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.1513 - accuracy: 0.9400 - val_loss: 3.0861 - val_accuracy: 0.5150\n","Epoch 7/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.1165 - accuracy: 0.9550 - val_loss: 2.5091 - val_accuracy: 0.4917\n","Epoch 8/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.0611 - accuracy: 0.9757 - val_loss: 3.8384 - val_accuracy: 0.5067\n","Epoch 9/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.0691 - accuracy: 0.9800 - val_loss: 3.0643 - val_accuracy: 0.4983\n","Epoch 10/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.0410 - accuracy: 0.9829 - val_loss: 4.4117 - val_accuracy: 0.4950\n","Epoch 1/10\n","175/175 [==============================] - 5s 15ms/step - loss: 0.6952 - accuracy: 0.4907 - val_loss: 0.6958 - val_accuracy: 0.4833\n","Epoch 2/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6940 - accuracy: 0.5100 - val_loss: 0.6926 - val_accuracy: 0.5167\n","Epoch 3/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6940 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5167\n","Epoch 4/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6930 - accuracy: 0.5129 - val_loss: 0.6993 - val_accuracy: 0.4833\n","Epoch 5/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6942 - accuracy: 0.5043 - val_loss: 0.6941 - val_accuracy: 0.4833\n","Epoch 6/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6941 - accuracy: 0.5086 - val_loss: 0.6927 - val_accuracy: 0.5167\n","Epoch 7/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6948 - accuracy: 0.4786 - val_loss: 0.6934 - val_accuracy: 0.4833\n","Epoch 8/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6943 - accuracy: 0.4786 - val_loss: 0.6951 - val_accuracy: 0.4833\n","Epoch 9/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6941 - accuracy: 0.5071 - val_loss: 0.6927 - val_accuracy: 0.5167\n","Epoch 10/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6942 - accuracy: 0.4957 - val_loss: 0.6938 - val_accuracy: 0.4833\n","Epoch 1/10\n","175/175 [==============================] - 6s 16ms/step - loss: 0.6986 - accuracy: 0.4850 - val_loss: 0.6935 - val_accuracy: 0.4833\n","Epoch 2/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6937 - accuracy: 0.4857 - val_loss: 0.6950 - val_accuracy: 0.4833\n","Epoch 3/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6940 - accuracy: 0.5071 - val_loss: 0.6926 - val_accuracy: 0.5167\n","Epoch 4/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6941 - accuracy: 0.4800 - val_loss: 0.6979 - val_accuracy: 0.4833\n","Epoch 5/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6940 - accuracy: 0.5014 - val_loss: 0.6955 - val_accuracy: 0.4833\n","Epoch 6/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6934 - accuracy: 0.5057 - val_loss: 0.6969 - val_accuracy: 0.4833\n","Epoch 7/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6941 - accuracy: 0.4971 - val_loss: 0.6926 - val_accuracy: 0.5167\n","Epoch 8/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6939 - accuracy: 0.5014 - val_loss: 0.6928 - val_accuracy: 0.5167\n","Epoch 9/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6941 - accuracy: 0.5071 - val_loss: 0.6933 - val_accuracy: 0.4833\n","Epoch 10/10\n","175/175 [==============================] - 2s 12ms/step - loss: 0.6950 - accuracy: 0.4829 - val_loss: 0.6940 - val_accuracy: 0.4833\n","performance update: [[50.292 50.    50.   ]\n"," [ 0.     0.     0.   ]\n"," [ 0.     0.     0.   ]\n"," [ 0.     0.     0.   ]\n"," [ 0.     0.     0.   ]]\n","num_samples: 2000\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","num_samples: 686\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","Frame features in train set: (2000, 2, 32, 32, 3)\n","Frame features in train set: (2000, 1)\n","Epoch 1/10\n","175/175 [==============================] - 7s 22ms/step - loss: 0.6975 - accuracy: 0.4879 - val_loss: 0.6967 - val_accuracy: 0.4833\n","Epoch 2/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6973 - accuracy: 0.5093 - val_loss: 0.6983 - val_accuracy: 0.4833\n","Epoch 3/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6935 - accuracy: 0.5029 - val_loss: 0.6930 - val_accuracy: 0.5167\n","Epoch 4/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6939 - accuracy: 0.5050 - val_loss: 0.6927 - val_accuracy: 0.5167\n","Epoch 5/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6922 - accuracy: 0.5229 - val_loss: 0.6951 - val_accuracy: 0.4650\n","Epoch 6/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6969 - accuracy: 0.5293 - val_loss: 0.7015 - val_accuracy: 0.4750\n","Epoch 7/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6931 - accuracy: 0.5214 - val_loss: 0.7027 - val_accuracy: 0.4833\n","Epoch 8/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6792 - accuracy: 0.5679 - val_loss: 0.7404 - val_accuracy: 0.5000\n","Epoch 9/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6068 - accuracy: 0.6629 - val_loss: 0.7932 - val_accuracy: 0.4817\n","Epoch 10/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.4635 - accuracy: 0.7800 - val_loss: 0.9953 - val_accuracy: 0.4767\n","Epoch 1/10\n","175/175 [==============================] - 7s 23ms/step - loss: 0.7003 - accuracy: 0.4943 - val_loss: 0.6946 - val_accuracy: 0.4833\n","Epoch 2/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6939 - accuracy: 0.5107 - val_loss: 0.6914 - val_accuracy: 0.5217\n","Epoch 3/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6623 - accuracy: 0.5986 - val_loss: 0.7194 - val_accuracy: 0.5200\n","Epoch 4/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.5444 - accuracy: 0.7336 - val_loss: 0.8477 - val_accuracy: 0.4900\n","Epoch 5/10\n","175/175 [==============================] - 3s 20ms/step - loss: 0.3179 - accuracy: 0.8621 - val_loss: 1.0434 - val_accuracy: 0.5500\n","Epoch 6/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.1397 - accuracy: 0.9507 - val_loss: 2.0220 - val_accuracy: 0.5550\n","Epoch 7/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.0509 - accuracy: 0.9821 - val_loss: 2.5039 - val_accuracy: 0.5550\n","Epoch 8/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.0264 - accuracy: 0.9936 - val_loss: 2.9778 - val_accuracy: 0.5500\n","Epoch 9/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 3.7124 - val_accuracy: 0.5467\n","Epoch 10/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 3.9182 - val_accuracy: 0.5583\n","Epoch 1/10\n","175/175 [==============================] - 7s 22ms/step - loss: 0.6989 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.4783\n","Epoch 2/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6932 - accuracy: 0.5150 - val_loss: 0.6926 - val_accuracy: 0.5167\n","Epoch 3/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.6691 - accuracy: 0.5829 - val_loss: 0.7088 - val_accuracy: 0.4783\n","Epoch 4/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.5557 - accuracy: 0.7114 - val_loss: 0.8106 - val_accuracy: 0.4717\n","Epoch 5/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.3952 - accuracy: 0.8143 - val_loss: 1.6003 - val_accuracy: 0.4900\n","Epoch 6/10\n","175/175 [==============================] - 3s 19ms/step - loss: 0.2278 - accuracy: 0.9007 - val_loss: 1.8619 - val_accuracy: 0.4667\n","Epoch 7/10\n","175/175 [==============================] - 3s 20ms/step - loss: 0.1321 - accuracy: 0.9493 - val_loss: 2.7581 - val_accuracy: 0.4983\n","Epoch 8/10\n","175/175 [==============================] - 4s 20ms/step - loss: 0.1055 - accuracy: 0.9579 - val_loss: 3.4591 - val_accuracy: 0.4650\n","Epoch 9/10\n","175/175 [==============================] - 4s 20ms/step - loss: 0.0533 - accuracy: 0.9814 - val_loss: 4.0434 - val_accuracy: 0.4817\n","Epoch 10/10\n","175/175 [==============================] - 3s 20ms/step - loss: 0.1105 - accuracy: 0.9707 - val_loss: 3.1529 - val_accuracy: 0.4750\n","performance update: [[50.292 50.    50.   ]\n"," [52.77  53.061 53.207]\n"," [ 0.     0.     0.   ]\n"," [ 0.     0.     0.   ]\n"," [ 0.     0.     0.   ]]\n","num_samples: 2000\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","num_samples: 686\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","Frame features in train set: (2000, 3, 32, 32, 3)\n","Frame features in train set: (2000, 1)\n","Epoch 1/10\n","175/175 [==============================] - 8s 30ms/step - loss: 0.7007 - accuracy: 0.5057 - val_loss: 0.6958 - val_accuracy: 0.4833\n","Epoch 2/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6917 - accuracy: 0.5250 - val_loss: 0.6709 - val_accuracy: 0.6250\n","Epoch 3/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.3456 - accuracy: 0.8443 - val_loss: 0.1545 - val_accuracy: 0.9483\n","Epoch 4/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.0690 - accuracy: 0.9779 - val_loss: 0.1829 - val_accuracy: 0.9367\n","Epoch 5/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.0348 - accuracy: 0.9843 - val_loss: 0.2818 - val_accuracy: 0.9283\n","Epoch 6/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.3448 - val_accuracy: 0.9300\n","Epoch 7/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.2356 - val_accuracy: 0.9333\n","Epoch 8/10\n","175/175 [==============================] - 5s 26ms/step - loss: 0.0262 - accuracy: 0.9893 - val_loss: 0.2077 - val_accuracy: 0.9450\n","Epoch 9/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.3014 - val_accuracy: 0.9300\n","Epoch 10/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.2998 - val_accuracy: 0.9433\n","Epoch 1/10\n","175/175 [==============================] - 9s 33ms/step - loss: 0.7059 - accuracy: 0.5043 - val_loss: 0.7001 - val_accuracy: 0.4700\n","Epoch 2/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6942 - accuracy: 0.5121 - val_loss: 0.6952 - val_accuracy: 0.4833\n","Epoch 3/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6928 - accuracy: 0.4921 - val_loss: 0.6964 - val_accuracy: 0.4833\n","Epoch 4/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6905 - accuracy: 0.5621 - val_loss: 0.7041 - val_accuracy: 0.5150\n","Epoch 5/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.5628 - accuracy: 0.7093 - val_loss: 0.2751 - val_accuracy: 0.8933\n","Epoch 6/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.1657 - accuracy: 0.9321 - val_loss: 0.1994 - val_accuracy: 0.9217\n","Epoch 7/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.0399 - accuracy: 0.9814 - val_loss: 0.3491 - val_accuracy: 0.9167\n","Epoch 8/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.3439 - val_accuracy: 0.9150\n","Epoch 9/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.0198 - accuracy: 0.9957 - val_loss: 0.4233 - val_accuracy: 0.9083\n","Epoch 10/10\n","175/175 [==============================] - 5s 27ms/step - loss: 4.3121e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9150\n","Epoch 1/10\n","175/175 [==============================] - 8s 30ms/step - loss: 0.6981 - accuracy: 0.5100 - val_loss: 0.6970 - val_accuracy: 0.4833\n","Epoch 2/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6946 - accuracy: 0.5014 - val_loss: 0.6929 - val_accuracy: 0.5167\n","Epoch 3/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6984 - accuracy: 0.4993 - val_loss: 0.6959 - val_accuracy: 0.4833\n","Epoch 4/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6943 - accuracy: 0.4829 - val_loss: 0.6934 - val_accuracy: 0.4833\n","Epoch 5/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6935 - accuracy: 0.5057 - val_loss: 0.6927 - val_accuracy: 0.5167\n","Epoch 6/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6940 - accuracy: 0.5057 - val_loss: 0.6980 - val_accuracy: 0.4833\n","Epoch 7/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6937 - accuracy: 0.5014 - val_loss: 0.6930 - val_accuracy: 0.5167\n","Epoch 8/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6950 - accuracy: 0.4900 - val_loss: 0.6943 - val_accuracy: 0.4833\n","Epoch 9/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6949 - accuracy: 0.4943 - val_loss: 0.6942 - val_accuracy: 0.4833\n","Epoch 10/10\n","175/175 [==============================] - 5s 27ms/step - loss: 0.6940 - accuracy: 0.5029 - val_loss: 0.6937 - val_accuracy: 0.4833\n","performance update: [[50.292 50.    50.   ]\n"," [52.77  53.061 53.207]\n"," [86.88  81.05  50.   ]\n"," [ 0.     0.     0.   ]\n"," [ 0.     0.     0.   ]]\n","num_samples: 2000\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","num_samples: 686\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","Frame features in train set: (2000, 4, 32, 32, 3)\n","Frame features in train set: (2000, 1)\n","Epoch 1/10\n","175/175 [==============================] - 9s 37ms/step - loss: 0.4421 - accuracy: 0.7279 - val_loss: 0.0592 - val_accuracy: 0.9817\n","Epoch 2/10\n","175/175 [==============================] - 6s 34ms/step - loss: 0.0537 - accuracy: 0.9814 - val_loss: 0.0834 - val_accuracy: 0.9717\n","Epoch 3/10\n","175/175 [==============================] - 6s 34ms/step - loss: 0.0643 - accuracy: 0.9843 - val_loss: 0.1779 - val_accuracy: 0.9583\n","Epoch 4/10\n","175/175 [==============================] - 6s 34ms/step - loss: 0.0247 - accuracy: 0.9929 - val_loss: 0.2659 - val_accuracy: 0.9367\n","Epoch 5/10\n","175/175 [==============================] - 6s 34ms/step - loss: 0.0338 - accuracy: 0.9914 - val_loss: 0.0371 - val_accuracy: 0.9917\n","Epoch 6/10\n","175/175 [==============================] - 6s 35ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0193 - val_accuracy: 0.9933\n","Epoch 7/10\n","175/175 [==============================] - 6s 34ms/step - loss: 1.2680e-04 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9933\n","Epoch 8/10\n","175/175 [==============================] - 6s 34ms/step - loss: 6.0681e-05 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9933\n","Epoch 9/10\n","175/175 [==============================] - 6s 34ms/step - loss: 3.8008e-05 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9933\n","Epoch 10/10\n","175/175 [==============================] - 6s 34ms/step - loss: 2.6321e-05 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9933\n","Epoch 1/10\n","175/175 [==============================] - 10s 37ms/step - loss: 0.4937 - accuracy: 0.7021 - val_loss: 0.0563 - val_accuracy: 0.9767\n","Epoch 2/10\n","175/175 [==============================] - 6s 34ms/step - loss: 0.0879 - accuracy: 0.9700 - val_loss: 0.0282 - val_accuracy: 0.9867\n","Epoch 3/10\n","175/175 [==============================] - 6s 34ms/step - loss: 0.0062 - accuracy: 0.9964 - val_loss: 0.0243 - val_accuracy: 0.9917\n","Epoch 4/10\n","175/175 [==============================] - 6s 34ms/step - loss: 3.0740e-04 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.9917\n","Epoch 5/10\n","175/175 [==============================] - 6s 34ms/step - loss: 9.5786e-05 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9917\n","Epoch 6/10\n","175/175 [==============================] - 6s 34ms/step - loss: 2.3973e-04 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9917\n","Epoch 7/10\n","175/175 [==============================] - 6s 34ms/step - loss: 1.1063e-05 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9917\n","Epoch 8/10\n","175/175 [==============================] - 6s 34ms/step - loss: 8.6879e-06 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9917\n","Epoch 9/10\n","175/175 [==============================] - 6s 34ms/step - loss: 7.1477e-06 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9917\n","Epoch 10/10\n","175/175 [==============================] - 6s 35ms/step - loss: 5.8739e-06 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9917\n","Epoch 1/10\n","175/175 [==============================] - 10s 37ms/step - loss: 0.7037 - accuracy: 0.5386 - val_loss: 0.6265 - val_accuracy: 0.6617\n","Epoch 2/10\n","175/175 [==============================] - 6s 34ms/step - loss: 0.1538 - accuracy: 0.9364 - val_loss: 0.0573 - val_accuracy: 0.9817\n","Epoch 3/10\n","175/175 [==============================] - 6s 35ms/step - loss: 0.0618 - accuracy: 0.9800 - val_loss: 0.0312 - val_accuracy: 0.9867\n","Epoch 4/10\n","175/175 [==============================] - 6s 35ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.0304 - val_accuracy: 0.9917\n","Epoch 5/10\n","175/175 [==============================] - 6s 34ms/step - loss: 3.1211e-04 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9917\n","Epoch 6/10\n","175/175 [==============================] - 6s 35ms/step - loss: 8.1896e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9917\n","Epoch 7/10\n","175/175 [==============================] - 6s 35ms/step - loss: 1.7171e-05 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9917\n","Epoch 8/10\n","175/175 [==============================] - 6s 34ms/step - loss: 1.2469e-05 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 0.9917\n","Epoch 9/10\n","175/175 [==============================] - 6s 34ms/step - loss: 9.4405e-06 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9917\n","Epoch 10/10\n","175/175 [==============================] - 6s 34ms/step - loss: 7.3649e-06 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9917\n","performance update: [[50.292 50.    50.   ]\n"," [52.77  53.061 53.207]\n"," [86.88  81.05  50.   ]\n"," [92.711 95.773 95.335]\n"," [ 0.     0.     0.   ]]\n","num_samples: 2000\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","num_samples: 686\n","0\n","100\n","200\n","300\n","400\n","500\n","600\n","Frame features in train set: (2000, 5, 32, 32, 3)\n","Frame features in train set: (2000, 1)\n","Epoch 1/10\n","175/175 [==============================] - 11s 44ms/step - loss: 0.7058 - accuracy: 0.4921 - val_loss: 0.6926 - val_accuracy: 0.5167\n","Epoch 2/10\n","175/175 [==============================] - 7s 42ms/step - loss: 0.6940 - accuracy: 0.4943 - val_loss: 0.6958 - val_accuracy: 0.4833\n","Epoch 3/10\n","175/175 [==============================] - 7s 42ms/step - loss: 0.6944 - accuracy: 0.5014 - val_loss: 0.6926 - val_accuracy: 0.5167\n","Epoch 4/10\n","175/175 [==============================] - 7s 42ms/step - loss: 0.6942 - accuracy: 0.5129 - val_loss: 0.6932 - val_accuracy: 0.4833\n","Epoch 5/10\n","175/175 [==============================] - 7s 41ms/step - loss: 0.6938 - accuracy: 0.4971 - val_loss: 0.6926 - val_accuracy: 0.5167\n","Epoch 6/10\n","175/175 [==============================] - 7s 41ms/step - loss: 0.6960 - accuracy: 0.4871 - val_loss: 0.6935 - val_accuracy: 0.4833\n","Epoch 7/10\n","175/175 [==============================] - 7s 42ms/step - loss: 0.6941 - accuracy: 0.5014 - val_loss: 0.6926 - val_accuracy: 0.5167\n","Epoch 8/10\n","175/175 [==============================] - 7s 42ms/step - loss: 0.6939 - accuracy: 0.5229 - val_loss: 0.6951 - val_accuracy: 0.4833\n","Epoch 9/10\n","175/175 [==============================] - 7s 41ms/step - loss: 0.6942 - accuracy: 0.4886 - val_loss: 0.6939 - val_accuracy: 0.4833\n","Epoch 10/10\n","175/175 [==============================] - 7s 41ms/step - loss: 0.6940 - accuracy: 0.4971 - val_loss: 0.6946 - val_accuracy: 0.4833\n","Epoch 1/10\n","175/175 [==============================] - 12s 45ms/step - loss: 0.5490 - accuracy: 0.6786 - val_loss: 0.0978 - val_accuracy: 0.9700\n","Epoch 2/10\n","175/175 [==============================] - 7s 42ms/step - loss: 0.0349 - accuracy: 0.9886 - val_loss: 0.0056 - val_accuracy: 0.9983\n","Epoch 3/10\n","175/175 [==============================] - 7s 42ms/step - loss: 0.0257 - accuracy: 0.9950 - val_loss: 0.0081 - val_accuracy: 0.9950\n","Epoch 4/10\n","175/175 [==============================] - 7s 42ms/step - loss: 1.5014e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 5/10\n","175/175 [==============================] - 7s 42ms/step - loss: 2.9325e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n","Epoch 6/10\n","175/175 [==============================] - 7s 41ms/step - loss: 1.9369e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n","Epoch 7/10\n","175/175 [==============================] - 7s 41ms/step - loss: 1.4024e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n","Epoch 8/10\n","175/175 [==============================] - 7s 42ms/step - loss: 1.0622e-05 - accuracy: 1.0000 - val_loss: 9.8326e-04 - val_accuracy: 1.0000\n","Epoch 9/10\n","175/175 [==============================] - 7s 41ms/step - loss: 8.2725e-06 - accuracy: 1.0000 - val_loss: 9.0059e-04 - val_accuracy: 1.0000\n","Epoch 10/10\n","175/175 [==============================] - 7s 41ms/step - loss: 6.5787e-06 - accuracy: 1.0000 - val_loss: 8.5579e-04 - val_accuracy: 1.0000\n","Epoch 1/10\n","175/175 [==============================] - 11s 45ms/step - loss: 0.7034 - accuracy: 0.5157 - val_loss: 0.6902 - val_accuracy: 0.6083\n","Epoch 2/10\n","175/175 [==============================] - 7s 41ms/step - loss: 0.3257 - accuracy: 0.8714 - val_loss: 0.0300 - val_accuracy: 0.9900\n","Epoch 3/10\n","175/175 [==============================] - 7s 41ms/step - loss: 0.0260 - accuracy: 0.9893 - val_loss: 0.0324 - val_accuracy: 0.9850\n","Epoch 4/10\n","175/175 [==============================] - 7s 42ms/step - loss: 0.0058 - accuracy: 0.9971 - val_loss: 0.0039 - val_accuracy: 1.0000\n","Epoch 5/10\n","175/175 [==============================] - 7s 42ms/step - loss: 7.7231e-04 - accuracy: 0.9993 - val_loss: 0.0162 - val_accuracy: 0.9917\n","Epoch 6/10\n","175/175 [==============================] - 7s 42ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0308 - val_accuracy: 0.9900\n","Epoch 7/10\n","175/175 [==============================] - 7s 42ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0037 - val_accuracy: 0.9983\n","Epoch 8/10\n","175/175 [==============================] - 7s 41ms/step - loss: 4.2594e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9950\n","Epoch 9/10\n","175/175 [==============================] - 7s 42ms/step - loss: 1.1892e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9983\n","Epoch 10/10\n","175/175 [==============================] - 7s 42ms/step - loss: 5.0169e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9983\n","performance update: [[50.292 50.    50.   ]\n"," [52.77  53.061 53.207]\n"," [86.88  81.05  50.   ]\n"," [92.711 95.773 95.335]\n"," [50.    96.793 94.752]]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}